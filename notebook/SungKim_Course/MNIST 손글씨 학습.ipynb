{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax를 이용한 MNIST 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 2.585537040\n",
      "Epoch: 0002 cost = 1.069761497\n",
      "Epoch: 0003 cost = 0.860287841\n",
      "Epoch: 0004 cost = 0.756047318\n",
      "Epoch: 0005 cost = 0.689340877\n",
      "Epoch: 0006 cost = 0.641480411\n",
      "Epoch: 0007 cost = 0.604843244\n",
      "Epoch: 0008 cost = 0.575857621\n",
      "Epoch: 0009 cost = 0.551710922\n",
      "Epoch: 0010 cost = 0.531530286\n",
      "Epoch: 0011 cost = 0.514342474\n",
      "Epoch: 0012 cost = 0.499376533\n",
      "Epoch: 0013 cost = 0.486139046\n",
      "Epoch: 0014 cost = 0.474116336\n",
      "Epoch: 0015 cost = 0.463867946\n",
      "Accuracy:  0.8878\n",
      "Label: [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD9CAYAAABzwKHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121867080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hyphthesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hyphthesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hyphthesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# 에폭\n",
    "training_epochs = 15 # 전체 데이터를 한번 다 학습시킨 것을 1 에폭이라 한다.\n",
    "batch_size = 100     # 한번에 몇개씩 학습시킬 것인가.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            # 배치 사이즈 100\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "    # 테스트 데이터를 이용해 정확도 검증\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    # 임의의 데이터를 뽑아 잘 예측하는지 확인해보기.\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    # label은 원-핫 인코딩으로 되어있으므로 가장 크기가 큰 인덱스가 곧 해당 숫자이다.\n",
    "    print(\"Label:\", sess.run(tf.arg_max(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.arg_max(hyphthesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer를 추가하여 정확도를 높여보자\n",
    "### + Xavier 초기화를 이용해 초기화 잘해보기\n",
    "### + Dropout을 이용해 over-fitting 방지하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 1.787995259\n",
      "Epoch: 0002 cost = 1.638308868\n",
      "Epoch: 0003 cost = 1.625795757\n",
      "Epoch: 0004 cost = 1.625590219\n",
      "Epoch: 0005 cost = 1.568509046\n",
      "Epoch: 0006 cost = 1.553394908\n",
      "Epoch: 0007 cost = 1.563160105\n",
      "Epoch: 0008 cost = 1.559503732\n",
      "Epoch: 0009 cost = 1.575938160\n",
      "Epoch: 0010 cost = 1.574792636\n",
      "Epoch: 0011 cost = 1.572664163\n",
      "Epoch: 0012 cost = 1.571084289\n",
      "Epoch: 0013 cost = 1.573846337\n",
      "Epoch: 0014 cost = 1.576273384\n",
      "Epoch: 0015 cost = 1.562760983\n",
      "Accuracy:  0.9174\n",
      "Label: [5]\n",
      "Prediction: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD9CAYAAABzwKHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kRfiApwg8kRfiBpP4XjFYngUKaJ9EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121664240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"layers__\", reuse=None) as scope:\n",
    "    # Xavier 초기화!! -> weight값 초기화를 잘해보자\n",
    "    # tf.Variable -> tf.get_variable\n",
    "    W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([512]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([512]))\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "    \n",
    "    W3 = tf.get_variable(\"W3\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([512]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "    \n",
    "    W4 = tf.get_variable(\"W4\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([512]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "    \n",
    "    W5 = tf.get_variable(\"W5\", shape=[512, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# 출력층에서는 softmax함수 사용\n",
    "hyphthesis = tf.nn.softmax(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hyphthesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hyphthesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# 에폭\n",
    "training_epochs = 15 # 전체 데이터를 한번 다 학습시킨 것을 1 에폭이라 한다.\n",
    "batch_size = 100     # 한번에 몇개씩 학습시킬 것인가.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            # 배치 사이즈 100\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "    # 테스트 데이터를 이용해 정확도 검증\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0}))\n",
    "    \n",
    "    # 임의의 데이터를 뽑아 잘 예측하는지 확인해보기.\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    # label은 원-핫 인코딩으로 되어있으므로 가장 크기가 큰 인덱스가 곧 해당 숫자이다.\n",
    "    print(\"Label:\", sess.run(tf.arg_max(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.arg_max(hyphthesis, 1), feed_dict={X: mnist.test.images[r:r+1], keep_prob: 1.0}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
